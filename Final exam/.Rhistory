View(mvt)
View(mvt)
View(mvt)
install.packages("e1071")
getwd()
getwd()
help("solve")
getwd()
apropos("lm")
find("lowess")
library(help=e1071)
log(50)
#simple calculation
log(50)
5+3
log(20); 3*35; 2+2
floor(5.3)
ceiling(5.3)
round(5.3)
round(5.9)
x <- 5
y = 2
print(x)
print(y)
x = 1:50
x
#assigning variables (variables cannot start with digit, cannot contain space in between)
x <- 5
y = 2
print(x)
print(y)
#creating vectors
x = 1:50
x
seq(0,8,0.2)
sum(z=1:50)
z
sum(ab <- 1250)
ab
a+boolean
a <- 4
a
str <- "abc"
str
boolean <- TRUE
boolean
a+str #gives error
a+boolean
str+boolean
str+a
x <- "2.5"
class(x)
as.numeric(x) + a
x+a
x <- c(1, 0.5, 4)
x
z <- vector("numeric", length = 50)
z
help(vector)
x <- c(1, 0.5, 4)
mean(x)
max(x)
quantile(x)
rep(4,9)
rep(1 : 7, 10)
rep(1:7, each=3)
rep(1:4, 1:4)
rep(1:5, 1:4)
x <- c(1, 0.5, 4)
y <- c(1, 1, 1)
x+y
x <- c(1, 0.5, 4)
y <- c(1, 1, 1, 1)
x+y
x <- c(1, 0.5, 4)
y <- c(1, 1, 1, 1)
y+x
a <- c(1,3,2,4,5,7,8,9,6,2,1,4)
a
a[1]
b <- a(c[1:4])
b <- a[c(1,4)]
b
a <- c(1,3,2,5,4,5,7,8,9,6,2,1,4)
b <- a[c(1,4)]
b
d <- a[1:4]
d
d[-1]
d
a>3
a/5
anyvector <- a>3
a[anyvector]
x <- 1:30
x[x>5]
help(rnbinom)
counts <- rnbinom(10000, mu = 0.92, size = 1.1)
counts[1:30]
table(counts)
setA <- c("a", "b", "c", "d", "e")
setB <- c("d", "e", "f", "g")
union(setA,setB)
intersect(setA,setB)
setdiff(setA,setB)
x <- list(1, "c", FALSE)
x
x <- list(col1 = 1:3, col2 = 4)
x
x[1]
x[[1]][2]
x[1]
x[1]
x[[1]]
m1 <- matrix(nrow=4, ncol=5)
m1
dim(m1)
m1 <- matrix(1:10, nrow=2, ncol=5)
m1
dim(m1)
matrix(data = c(1,2,3,4,5), byrow=TRUE, nrow=2)
matrix(data = c(1,2,3,4,5), byrow=TRUE, nrow=2)
matrix(data = c(1,2,3,4,5), byrow=TRUE, nrow=2)
matrix(data = c(1,2,3,4), byrow=TRUE, nrow=2)
x <- matrix(1:10,2,5)
x
x[1,1]
x[1,]
x[,2]
X <- 1:6
y <- 12:17
cbind(x,y)
rbind(x,y)
X <- 1:6
y <- 12:17
cbind(x,y)
rbind(x,y)
x <- data.frame(col1 = 1:20, col2 = c(T,F,F,T))
x
nrow(x)
ncol(x)
str(x) #structure of data frame
x[2:5,1]
#for loop
x <- c("a","b","c")
for(i in seq_along(x))
print(x[i])
for(letter in x)
print(x[letter])
func1 <- function(a,b) {
a+b
}
func1(2+2)
func1(2,2)
square.it <- function(x) {
square <- x*x
return(square)
}
squareit(5)
square.it(5)
liverdata = read.csv("liverDisorder.csv", header = FALSE, col.names = c("mcv", "aap", "sgpt", "sgot", "gammagt", "drinks", "selector"))
setwd("E:/Data-Mining/Final exam")
liverdata = read.csv("liverDisorder.csv", header = FALSE, col.names = c("mcv", "aap", "sgpt", "sgot", "gammagt", "drinks", "selector"))
View(liverdata)
liverdata$drinks = cut(liverdata$drinks, breaks = c(0,5,10,15,20), labels = c('C1', 'C2', 'C3', 'C4'), right = FALSE)
knnfit = knn(traindata, testdata, k = 1)
library(class)
knnfit = knn(traindata, testdata, k = 1)
liverdata = read.csv("liverDisorder.csv", header = FALSE, col.names = c("mcv", "aap", "sgpt", "sgot", "gammagt", "drinks", "selector"))
#converting the decision attribute into classes
liverdata$drinks = cut(liverdata$drinks, breaks = c(0,5,10,15,20), labels = c('C1', 'C2', 'C3', 'C4'), right = FALSE)
#traing and test sets
traindata = subset(liverdata, liverdata$selector == 1)
testdata = subset(liverdata, liverdata$selector == 0)
library(class)
knnfit = knn(traindata, testdata, k = 1)
liverdata = na.omit(liverdata)
knnfit = knn(traindata, testdata, k = 1)
count(is.na(liverdata))
sum(is.na(liverdata))
knnfit = knn(traindata, testdata, as.factor(c(-1,1)))
liverdata = na.omit(liverdata)
knnfit = knn(traindata, testdata, k = 1)
#traing and test sets
traindata = subset(liverdata, liverdata$selector == 1)
testdata = subset(liverdata, liverdata$selector == 2)
liverdata = na.omit(liverdata)
library(class)
knnfit = knn(traindata, testdata, k = 1)
View(traindata)
x = traindata[,6]
y = traindata[,1:5]
knnfit = knn(x,y,k = 1)
knnfit = knn(x,y,x,k = 1)
y = traindata[,1:5]
#converting the decision attribute into classes
liverdata$drinks = cut(liverdata$drinks, breaks = c(0,5,10,15,20,25), labels = c('C1', 'C2', 'C3', 'C4', 'C4'), right = FALSE)
liverdata = read.csv("liverDisorder.csv", header = FALSE, col.names = c("mcv", "aap", "sgpt", "sgot", "gammagt", "drinks", "selector"))
#converting the decision attribute into classes
liverdata$drinks = cut(liverdata$drinks, breaks = c(0,5,10,15,20,25), labels = c('C1', 'C2', 'C3', 'C4', 'C4'), right = FALSE)
#traing and test sets
traindata = subset(liverdata, liverdata$selector == 1)
testdata = subset(liverdata, liverdata$selector == 2)
y_train = traindata[,6, drop = TRUE]
y_test = testdata[,6, drop = TRUE]
x_train <- subset(traindata, select = -c(selector, drinks))
x_test <- subset(testdata, select = -c(selector, drinks))
y_train = traindata[,6, drop = TRUE]
y_test = testdata[,6, drop = TRUE]
knnfit = knn(x_train, x_train, y_train, k = 1)
1-sum(y_test==fit1)/length(y_test)
1-sum(y_test==knnfit)/length(y_test)
#knn for k=1
knnfit2 = knn(x_train, x_train, y_train, k = 2)
1-sum(y_test==knnfit2)/length(y_test)
#knn for k=1
knnfit3 = knn(x_train, x_train, y_train, k = 3)
1-sum(y_test==knnfit3)/length(y_test)
knnfit = knn(x_train, x_train, y_train, k = 1)
1-sum(y_train==knnfit)/length(y_train) #0.52
1-sum(y_train==knnfit2)/length(y_train) #0.505
1-sum(y_train==knnfit3)/length(y_train) #0.47
#For Test Data
#knn for k=1
knnfit = knn(x_test, x_test, y_test, k = 1)
1-sum(y_test==knnfit)/length(y_test) #0.52
#knn for k=2
knnfit2 = knn(x_test, x_test, y_test, k = 2)
1-sum(y_test==knnfit2)/length(y_test) #0.505
#knn for k=3
knnfit3 = knn(x_test, x_test, y_test, k = 3)
1-sum(y_test==knnfit3)/length(y_test) #0.47
liverdata = read.csv("liverDisorder.csv", header = FALSE, col.names = c("mcv", "aap", "sgpt", "sgot", "gammagt", "drinks", "selector"))
#converting the decision attribute into classes
liverdata$drinks = cut(liverdata$drinks, breaks = c(0,5,10,15,20,25), labels = c('C1', 'C2', 'C3', 'C4', 'C4'), right = FALSE)
liverdata = na.omit(liverdata)
#traing and test sets
traindata = subset(liverdata, liverdata$selector == 1)
testdata = subset(liverdata, liverdata$selector == 2)
x_train <- subset(traindata, select = -c(selector, drinks))
x_test <- subset(testdata, select = -c(selector, drinks))
y_train = traindata[,6, drop = TRUE]
y_test = testdata[,6, drop = TRUE]
library(e1071)
#For training
fit = svm(x_train, y_train)
#For training
fittrain = svm(x_train, y_train)
1-sum(y_train==predict(fittrain,x_train))/length(y_train)   #0.2027
#For test data
fittest = svm(x_test, y_test)
1-sum(y_test==predict(fittest,x_test))/length(y_test)    #0.265
setwd("E:/Data-Mining/Final exam")
knnfit<-knn(fit$centers, x, as.factor(c(1,2,3,4))
knnfit<-knn(fit$centers, x, as.factor(c(1,2,3,4)))
library(class)
knnfit<-knn(fit$centers, x, as.factor(c(1,2,3,4)))
leverdata = read.csv("liverDisorder.csv", header = FALSE, col.names = c("mcv", "aap", "sgpt", "sgot", "gammagt", "drinks", "selector"))
res = cor(leverdata)
#taking mcv and gammagt columns
x = leverdata[, c("mcv", "gammagt")]
#kmeans with 4 clusters and plotting them
fit = kmeans(x, 4)
knnfit<-knn(fit$centers, x, as.factor(c(1,2,3,4)))
View(leverdata)
y = leverdata$drinks
1-sum(knnfit==y)/length(y)
